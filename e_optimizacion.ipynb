{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ceeb24-d1e0-4b68-8504-a25f4b3ff076",
   "metadata": {},
   "source": [
    "<h2><font color=\"#000000\" size=6>Minería de datos</font></h2>\n",
    "<h1><font color=\"#000000\" size=5>PEC 4 - Random Forest</font></h1>\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#000000\" size=3>Estudiante: Fernando H. Nasser-Eddine López</font><br>\n",
    "<font color=\"#000000\" size=3>Máster Universitario en Investigación en Inteligencia Artificial (MUIIA)</font><br>\n",
    "<font color=\"#000000\" size=3>Mayo 2025</font><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508a27a-8ef5-45e7-868b-c8fad5470140",
   "metadata": {},
   "source": [
    "<h2><font color=\"#000000\" size=5>Índice</font></h2><a id=\"indice\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8722655-7156-482e-815e-3e3b522a9a83",
   "metadata": {},
   "source": [
    "* [4. Fase de optimización](#section4)\n",
    "    * [4.1. Implementación de búsqueda exhaustiva de hiperparámetros mediante validación cruzada](#section41)\n",
    "        * [4.1.1. Optimización del modelo 1 (Random Forrest)](#section411)\n",
    "        * [4.1.2. Optimización del modelo 2 (Extra Trees)](#section412)\n",
    "        * [4.1.3. Optimización del modelo 3 (Bagging)](#section413)\n",
    "    * [4.2. Evaluación de los modelos optimizados](#section42)\n",
    "* [5. Conclusiones](#section5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a1df3-4046-4714-abac-fd3da06cc22c",
   "metadata": {},
   "source": [
    "# <font color=\"#000000\"> 4. Fase de optimización</font><a id=\"section4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5a7c1-9f14-4863-813a-ae9dc89bfbae",
   "metadata": {},
   "source": [
    "### <font color=\"#000000\">Importación de librerías</font><a id=\"section11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232241c7-c8bc-47cd-8dfb-be917de7c973",
   "metadata": {},
   "source": [
    "\n",
    "En esta sección realizamos la importación de todas las librerías que utilizaremos a lo largo del análisis. Principalmente, usamos pandas para la manipulación de datos, matplotlib y seaborn para visualizaciones, así como scikit-learn para los algoritmos de aprendizaje automático y evaluación de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb833b5-88dd-45b0-9638-4e8abb69bce2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# Importación de las librerías necesarias\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import nbimporter\n",
    "from a_analisis import detect_outliers_comprehensive\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                            confusion_matrix, roc_auc_score, classification_report, \n",
    "                            roc_curve, auc)\n",
    "\n",
    "# Modelos base\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Modelos ensemble\n",
    "from sklearn.ensemble import (RandomForestClassifier, BaggingClassifier, \n",
    "                             ExtraTreesClassifier, AdaBoostClassifier)\n",
    "\n",
    "# Explicabilidad\n",
    "import shap\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# Evitar warnings innecesarios\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f3f1fb-bf2d-455a-be1e-8283b82f63f8",
   "metadata": {},
   "source": [
    "Para seleccionar los tres mejores modelos ensemble, podemos establecer algunos criterios como:\n",
    "1. **Rendimiento cuantitativo**: Exactitud, precisión, sensibilidad y F1-Score\n",
    "2. **Estabilidad**: Diferencia entre rendimiento en entrenamiento y prueba\n",
    "3. **Interpretabilidad**: Capacidad para proporcionar importancia de características\n",
    "4. **Versatilidad**: Rendimiento tanto con datos originales como preprocesados\n",
    "\n",
    "| Modelo | Rendimiento (Datos prep.) | Estabilidad | Interpretabilidad | Versatilidad |\n",
    "|--------|---------------------------|-------------|-------------------|--------------|\n",
    "| Random Forest | 100% en todas las métricas | Alta | Alta | Buena (93.56% en original) |\n",
    "| Bagging-DT | 98.83% exactitud | Media | Media | Buena (94.74% en original) |\n",
    "| Bagging-LR | 100% en todas las métricas | Alta | Baja | Buena (94.15% en original) |\n",
    "| Bagging-SVM | 100% en todas las métricas | Alta | Baja | Baja (91.23% en original) |\n",
    "| Extra Trees | 100% en todas las métricas | Alta | Alta | Muy buena (97.08% en original) |\n",
    "\n",
    "Basándonos en estos criterios, los tres mejores modelos podrían ser:\n",
    "\n",
    "1. **Extra Trees**: Rendimiento perfecto con datos preprocesados y el mejor desempeño con datos originales (97.08%), combinado con alta interpretabilidad mediante su ranking de importancia de características. Su mayor capacidad para manejar datos sin preprocesar lo convierte en el modelo más versátil.\n",
    "\n",
    "2. **Random Forest**: Rendimiento perfecto con datos preprocesados, alta interpretabilidad y buena versatilidad. Proporciona una perspectiva complementaria a Extra Trees en cuanto a importancia de variables.\n",
    "\n",
    "3. **Bagging con Regresión Logística**: Combina las ventajas del ensemble con un clasificador lineal base, logrando rendimiento perfecto con datos preprocesados y buena versatilidad (94.15% con datos originales). Representa una aproximación distinta a los modelos basados en árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4855f5d-e7b2-4dbf-8232-8768e03b2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelos para optimización\n",
    "with open('data/models/models_for_optimization.pkl', 'rb') as f:\n",
    "    models_data = pickle.load(f)\n",
    "\n",
    "# Extraer modelos y datos\n",
    "rf_model = models_data['random_forest']\n",
    "et_model = models_data['extra_trees']\n",
    "bagging_lr = models_data['bagging_lr']\n",
    "X_train_model = models_data['X_train']\n",
    "X_test_model = models_data['X_test']\n",
    "y_train_model = models_data['y_train']\n",
    "y_test_model = models_data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176011d-4406-4fd2-a773-c219e0ce05ab",
   "metadata": {},
   "source": [
    "\n",
    "## <font color=\"#000000\"> 4.1. Implementación de búsqueda exhaustiva de hiperparámetros mediante validación cruzada</font><a id=\"section41\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca909e4-67d8-4b76-bfc9-174a8cc548bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(model_type, param_grid, X_train, y_train, X_test, y_test, random_state=42):\n",
    "    \"\"\"\n",
    "    Optimiza un modelo ensemble buscando la configuración más simple que mantenga 100% de exactitud.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Generamos todas las combinaciones de hiperparámetros\n",
    "    param_keys = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    \n",
    "    # Función para calcular la complejidad del modelo\n",
    "    def get_complexity(params):\n",
    "        if model_type == 'RandomForest' or model_type == 'ExtraTrees':\n",
    "            max_depth = params.get('max_depth')\n",
    "            max_depth_value = float('inf') if max_depth is None else max_depth\n",
    "            return params['n_estimators'] * max_depth_value\n",
    "        elif model_type == 'BaggingLR':\n",
    "            return params['n_estimators'] * (1 if params.get('max_samples') == 1.0 else params.get('max_samples'))\n",
    "    \n",
    "    from itertools import product\n",
    "    for values in product(*param_values):\n",
    "        params = dict(zip(param_keys, values))\n",
    "        \n",
    "        # Creamos el modelo con los hiperparámetros actuales\n",
    "        if model_type == 'RandomForest':\n",
    "            model = RandomForestClassifier(random_state=random_state, **params)\n",
    "        elif model_type == 'ExtraTrees':\n",
    "            model = ExtraTreesClassifier(random_state=random_state, **params)\n",
    "        elif model_type == 'BaggingLR':\n",
    "            base_estimator = LogisticRegression(max_iter=1000, random_state=random_state)\n",
    "            model = BaggingClassifier(estimator=base_estimator, random_state=random_state, **params)\n",
    "        \n",
    "        # Evaluación con validación cruzada\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "        \n",
    "        # Evaluación en conjunto de prueba\n",
    "        model.fit(X_train, y_train)\n",
    "        test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        \n",
    "        # Guardamos resultados\n",
    "        result = params.copy()\n",
    "        result.update({\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'test_acc': test_acc,\n",
    "            'complexity': get_complexity(params)\n",
    "        })\n",
    "        # Guardamos también los tipos originales de cada parámetro para restaurarlos después\n",
    "        result['param_types'] = {k: type(v) for k, v in params.items()}\n",
    "        results.append(result)\n",
    "    \n",
    "    # Convertimos a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Filtramos modelos que alcanzan 100% de exactitud\n",
    "    perfect_models = results_df[results_df['test_acc'] == 1.0]\n",
    "    \n",
    "    if len(perfect_models) > 0:\n",
    "        # Ordenamos por complejidad y estabilidad\n",
    "        perfect_models = perfect_models.sort_values(['complexity', 'cv_std'], ascending=[True, True])\n",
    "        best_params_row = perfect_models.iloc[0]\n",
    "        \n",
    "        # Extraemos y corregimos tipos de los parámetros\n",
    "        best_params = {}\n",
    "        param_types = best_params_row['param_types']\n",
    "        for k in param_keys:\n",
    "            value = best_params_row[k]\n",
    "            # Restauramos el tipo original\n",
    "            if k == 'max_depth' and value is None:\n",
    "                best_params[k] = None\n",
    "            elif param_types[k] == int:\n",
    "                best_params[k] = int(value)\n",
    "            elif param_types[k] == float:\n",
    "                best_params[k] = float(value)\n",
    "            elif param_types[k] == bool:\n",
    "                best_params[k] = bool(value)\n",
    "            else:\n",
    "                best_params[k] = value\n",
    "        \n",
    "        # Creamos el mejor modelo con los parámetros corregidos\n",
    "        if model_type == 'RandomForest':\n",
    "            best_model = RandomForestClassifier(random_state=random_state, **best_params)\n",
    "        elif model_type == 'ExtraTrees':\n",
    "            best_model = ExtraTreesClassifier(random_state=random_state, **best_params)\n",
    "        elif model_type == 'BaggingLR':\n",
    "            base_estimator = LogisticRegression(max_iter=1000, random_state=random_state)\n",
    "            best_model = BaggingClassifier(estimator=base_estimator, random_state=random_state, **best_params)\n",
    "        \n",
    "        best_model.fit(X_train, y_train)\n",
    "    else:\n",
    "        # Si ningún modelo alcanza 100%, ordenamos por exactitud en prueba\n",
    "        results_df = results_df.sort_values(['test_acc', 'complexity', 'cv_std'], \n",
    "                                          ascending=[False, True, True])\n",
    "        best_params_row = results_df.iloc[0]\n",
    "        \n",
    "        # Extraemos y corregimos tipos de los parámetros\n",
    "        best_params = {}\n",
    "        param_types = best_params_row['param_types']\n",
    "        for k in param_keys:\n",
    "            value = best_params_row[k]\n",
    "            # Restauramos el tipo original\n",
    "            if k == 'max_depth' and value is None:\n",
    "                best_params[k] = None\n",
    "            elif param_types[k] == int:\n",
    "                best_params[k] = int(value)\n",
    "            elif param_types[k] == float:\n",
    "                best_params[k] = float(value)\n",
    "            elif param_types[k] == bool:\n",
    "                best_params[k] = bool(value)\n",
    "            else:\n",
    "                best_params[k] = value\n",
    "        \n",
    "        # Creamos el mejor modelo con los parámetros corregidos\n",
    "        if model_type == 'RandomForest':\n",
    "            best_model = RandomForestClassifier(random_state=random_state, **best_params)\n",
    "        elif model_type == 'ExtraTrees':\n",
    "            best_model = ExtraTreesClassifier(random_state=random_state, **best_params)\n",
    "        elif model_type == 'BaggingLR':\n",
    "            base_estimator = LogisticRegression(max_iter=1000, random_state=random_state)\n",
    "            best_model = BaggingClassifier(estimator=base_estimator, random_state=random_state, **best_params)\n",
    "        \n",
    "        best_model.fit(X_train, y_train)\n",
    "    \n",
    "    return best_model, best_params, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d0b0f-b6d0-4dac-bf29-2d2f8ee01aeb",
   "metadata": {},
   "source": [
    "### <font color=\"#000000\"> 4.1.1. Optimización del modelo 1 (Random Forrest)</font><a id=\"section421\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6cfc7e-5a04-4946-9e5e-d56b77d66a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando Random Forest...\n"
     ]
    }
   ],
   "source": [
    "# Evaluación de diferentes configuraciones de Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 25, 50, 100],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Optimización de Random Forest\n",
    "print(\"Optimizando Random Forest...\")\n",
    "best_rf, best_rf_params, rf_results = optimize_model(\n",
    "    'RandomForest', param_grid_rf, X_train_model, y_train_model, X_test_model, y_test_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584903ed-3124-4bd2-9de3-cf789401dad9",
   "metadata": {},
   "source": [
    "### <font color=\"#000000\"> 4.1.2. Optimización del modelo 2 (Extra Trees)</font><a id=\"section422\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e67e7e-7532-4637-8a00-8272a072b5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando Extra Trees...\n"
     ]
    }
   ],
   "source": [
    "# Definimos el grid de hiperparámetros para Extra Trees\n",
    "param_grid_et = {\n",
    "    'n_estimators': [10, 25, 50, 100],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Optimización de Extra Trees\n",
    "print(\"Optimizando Extra Trees...\")\n",
    "best_et, best_et_params, et_results = optimize_model(\n",
    "    'ExtraTrees', param_grid_et, X_train_model, y_train_model, X_test_model, y_test_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04a3e4-bc79-4db5-ab3a-51134c683469",
   "metadata": {},
   "source": [
    "### <font color=\"#000000\"> 4.1.3. Optimización del modelo 3 (Bagging)</font><a id=\"section423\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9714e237-cb7f-431e-a563-3b2a6aad5dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando Bagging con Regresión Logística...\n"
     ]
    }
   ],
   "source": [
    "# Definimos el grid de hiperparámetros para Bagging\n",
    "param_grid_bagging_lr = {\n",
    "    'n_estimators': [10, 25, 50, 100],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "# Optimización de Bagging con Regresión Logística\n",
    "print(\"Optimizando Bagging con Regresión Logística...\")\n",
    "best_bagging_lr, best_bagging_lr_params, bagging_lr_results = optimize_model(\n",
    "    'BaggingLR', param_grid_bagging_lr, X_train_model, y_train_model, X_test_model, y_test_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be6df9d-71c4-4405-9af4-5de262466185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuración óptima para Random Forest:\n",
      "n_estimators: 25\n",
      "max_depth: 5\n",
      "min_samples_split: 2\n",
      "min_samples_leaf: 2\n",
      "\n",
      "Configuración óptima para Extra Trees:\n",
      "n_estimators: 25\n",
      "max_depth: 5\n",
      "min_samples_split: 10\n",
      "min_samples_leaf: 1\n",
      "\n",
      "Configuración óptima para Bagging con LR:\n",
      "n_estimators: 10\n",
      "max_samples: 0.5\n",
      "max_features: 1.0\n",
      "bootstrap: False\n",
      "bootstrap_features: False\n"
     ]
    }
   ],
   "source": [
    "# Presentación de resultados\n",
    "for model_name, params in [(\"Random Forest\", best_rf_params), \n",
    "                          (\"Extra Trees\", best_et_params), \n",
    "                          (\"Bagging con LR\", best_bagging_lr_params)]:\n",
    "    print(f\"\\nConfiguración óptima para {model_name}:\")\n",
    "    for param, value in params.items():\n",
    "        if param in ['cv_mean', 'cv_std', 'test_acc', 'complexity']:\n",
    "            if param.startswith('cv_') or param == 'test_acc':\n",
    "                print(f\"{param}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"{param}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2bf00-9943-4594-ac6a-15b7bf63353d",
   "metadata": {},
   "source": [
    "### <font color=\"#000000\"> 4.1.4. Evaluación de los modelos optimizados</font><a id=\"section414\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86f062a4-5ffc-4299-bbed-560c1e318902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Evaluación de modelos optimizados\n",
      "\n",
      "Random Forest optimizado\n",
      "Configuración: n_estimators=25, max_depth=5, min_samples_split=2, min_samples_leaf=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy Train</th>\n",
       "      <th>Accuracy Test</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest optimizado</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Modelo  Accuracy Train  Accuracy Test  Precision  Recall  \\\n",
       "0  Random Forest optimizado             1.0       0.994152   0.990741     1.0   \n",
       "\n",
       "   F1-Score  \n",
       "0  0.995349  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicción Maligno (0)</th>\n",
       "      <th>Predicción Benigno (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Maligno (0)</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benigno (1)</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicción Maligno (0)  Predicción Benigno (1)\n",
       "Maligno (0)                      63                       1\n",
       "Benigno (1)                       0                     107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extra Trees optimizado\n",
      "Configuración: n_estimators=25, max_depth=5, min_samples_split=10, min_samples_leaf=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy Train</th>\n",
       "      <th>Accuracy Test</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extra Trees optimizado</td>\n",
       "      <td>0.997487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Modelo  Accuracy Train  Accuracy Test  Precision  Recall  \\\n",
       "0  Extra Trees optimizado        0.997487            1.0        1.0     1.0   \n",
       "\n",
       "   F1-Score  \n",
       "0       1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicción Maligno (0)</th>\n",
       "      <th>Predicción Benigno (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Maligno (0)</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benigno (1)</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicción Maligno (0)  Predicción Benigno (1)\n",
       "Maligno (0)                      64                       0\n",
       "Benigno (1)                       0                     107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bagging con Regresión Logística optimizado\n",
      "Configuración: n_estimators=10, max_samples=0.5, max_features=1.0, bootstrap=False, bootstrap_features=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy Train</th>\n",
       "      <th>Accuracy Test</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging con Regresión Logística optimizado</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Modelo  Accuracy Train  Accuracy Test  \\\n",
       "0  Bagging con Regresión Logística optimizado             1.0            1.0   \n",
       "\n",
       "   Precision  Recall  F1-Score  \n",
       "0        1.0     1.0       1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicción Maligno (0)</th>\n",
       "      <th>Predicción Benigno (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Maligno (0)</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benigno (1)</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicción Maligno (0)  Predicción Benigno (1)\n",
       "Maligno (0)                      64                       0\n",
       "Benigno (1)                       0                     107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabla 3.5. Métricas de rendimiento de modelos optimizados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy Train</th>\n",
       "      <th>Accuracy Test</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest optimizado</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extra Trees optimizado</td>\n",
       "      <td>0.997487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagging-LR optimizado</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Modelo  Accuracy Train  Accuracy Test  Precision  Recall  \\\n",
       "0  Random Forest optimizado        1.000000       0.994152   0.990741     1.0   \n",
       "1    Extra Trees optimizado        0.997487       1.000000   1.000000     1.0   \n",
       "2     Bagging-LR optimizado        1.000000       1.000000   1.000000     1.0   \n",
       "\n",
       "   F1-Score  \n",
       "0  0.995349  \n",
       "1  1.000000  \n",
       "2  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluación de modelos optimizados\n",
    "print(\"# Evaluación de modelos optimizados\")\n",
    "\n",
    "# Función para evaluar y mostrar resultados detallados\n",
    "def evaluate_optimized_model(model, model_name):\n",
    "    model.fit(X_train_model, y_train_model)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_train = model.predict(X_train_model)\n",
    "    y_pred_test = model.predict(X_test_model)\n",
    "    \n",
    "    # Métricas en entrenamiento\n",
    "    acc_train = accuracy_score(y_train_model, y_pred_train)\n",
    "    \n",
    "    # Métricas en prueba\n",
    "    acc_test = accuracy_score(y_test_model, y_pred_test)\n",
    "    prec = precision_score(y_test_model, y_pred_test)\n",
    "    rec = recall_score(y_test_model, y_pred_test)\n",
    "    f1 = f1_score(y_test_model, y_pred_test)\n",
    "    \n",
    "    # Crear un DataFrame con los resultados\n",
    "    results_df = pd.DataFrame({\n",
    "        'Modelo': [model_name],\n",
    "        'Accuracy Train': [acc_train],\n",
    "        'Accuracy Test': [acc_test],\n",
    "        'Precision': [prec],\n",
    "        'Recall': [rec],\n",
    "        'F1-Score': [f1]\n",
    "    })\n",
    "    \n",
    "    # Mostrar el DataFrame\n",
    "    display(results_df)\n",
    "    \n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(y_test_model, y_pred_test)\n",
    "\n",
    "    # Crear un DataFrame para la matriz de confusión\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                        index=['Maligno (0)', 'Benigno (1)'], \n",
    "                        columns=['Predicción Maligno (0)', 'Predicción Benigno (1)'])\n",
    "        \n",
    "    # Mostrar la matriz de confusión como tabla\n",
    "    display(cm_df)\n",
    "    \n",
    "    return {\n",
    "        'accuracy_train': acc_train,\n",
    "        'accuracy_test': acc_test,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Evaluamos cada modelo optimizado\n",
    "print(\"\\nRandom Forest optimizado\")\n",
    "print(f\"Configuración: n_estimators={best_rf_params['n_estimators']}, max_depth={best_rf_params['max_depth']}, \"\n",
    "      f\"min_samples_split={best_rf_params['min_samples_split']}, min_samples_leaf={best_rf_params['min_samples_leaf']}\")\n",
    "rf_opt_metrics = evaluate_optimized_model(best_rf, \"Random Forest optimizado\")\n",
    "\n",
    "print(\"\\nExtra Trees optimizado\")\n",
    "print(f\"Configuración: n_estimators={best_et_params['n_estimators']}, max_depth={best_et_params['max_depth']}, \"\n",
    "      f\"min_samples_split={best_et_params['min_samples_split']}, min_samples_leaf={best_et_params['min_samples_leaf']}\")\n",
    "et_opt_metrics = evaluate_optimized_model(best_et, \"Extra Trees optimizado\")\n",
    "\n",
    "print(\"\\nBagging con Regresión Logística optimizado\")\n",
    "print(f\"Configuración: n_estimators={best_bagging_lr_params['n_estimators']}, max_samples={best_bagging_lr_params['max_samples']}, \"\n",
    "      f\"max_features={best_bagging_lr_params['max_features']}, bootstrap={best_bagging_lr_params['bootstrap']}, \"\n",
    "      f\"bootstrap_features={best_bagging_lr_params['bootstrap_features']}\")\n",
    "bagging_lr_opt_metrics = evaluate_optimized_model(best_bagging_lr, \"Bagging con Regresión Logística optimizado\")\n",
    "\n",
    "# Tabla comparativa de métricas\n",
    "optimized_comparison = pd.DataFrame({\n",
    "    'Modelo': ['Random Forest optimizado', 'Extra Trees optimizado', 'Bagging-LR optimizado'],\n",
    "    'Accuracy Train': [rf_opt_metrics['accuracy_train'], et_opt_metrics['accuracy_train'], bagging_lr_opt_metrics['accuracy_train']],\n",
    "    'Accuracy Test': [rf_opt_metrics['accuracy_test'], et_opt_metrics['accuracy_test'], bagging_lr_opt_metrics['accuracy_test']],\n",
    "    'Precision': [rf_opt_metrics['precision'], et_opt_metrics['precision'], bagging_lr_opt_metrics['precision']],\n",
    "    'Recall': [rf_opt_metrics['recall'], et_opt_metrics['recall'], bagging_lr_opt_metrics['recall']],\n",
    "    'F1-Score': [rf_opt_metrics['f1'], et_opt_metrics['f1'], bagging_lr_opt_metrics['f1']]\n",
    "})\n",
    "\n",
    "print(\"\\nTabla 3.5. Métricas de rendimiento de modelos optimizados:\")\n",
    "display(optimized_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a8459a5-fefc-4774-a8b4-3c3619e2bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 3.6. Comparación de configuraciones: modelos originales vs optimizados\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>max_features</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>bootstrap_features</th>\n",
       "      <th>Accuracy Test</th>\n",
       "      <th>Reducción Complejidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>93.56</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (opt)</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>99.42</td>\n",
       "      <td>~75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>97.08</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extra Trees (opt)</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100.00</td>\n",
       "      <td>~75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging con LR</td>\n",
       "      <td>100</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>94.15</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bagging con LR (opt)</td>\n",
       "      <td>10</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.00</td>\n",
       "      <td>~90%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Modelo  n_estimators max_depth min_samples_split  \\\n",
       "0         Random Forest           100      None                 2   \n",
       "1   Random Forest (opt)            25         5                 2   \n",
       "2           Extra Trees           100      None                 2   \n",
       "3     Extra Trees (opt)            25         5                10   \n",
       "4        Bagging con LR           100       N/A               N/A   \n",
       "5  Bagging con LR (opt)            10       N/A               N/A   \n",
       "\n",
       "  min_samples_leaf max_samples max_features bootstrap bootstrap_features  \\\n",
       "0                1         N/A          N/A      True              False   \n",
       "1                2         N/A          N/A      True              False   \n",
       "2                1         N/A          N/A      True              False   \n",
       "3                1         N/A          N/A      True              False   \n",
       "4              N/A         1.0          1.0      True              False   \n",
       "5              N/A         0.5          1.0     False              False   \n",
       "\n",
       "   Accuracy Test Reducción Complejidad  \n",
       "0          93.56                   N/A  \n",
       "1          99.42                  ~75%  \n",
       "2          97.08                   N/A  \n",
       "3         100.00                  ~75%  \n",
       "4          94.15                   N/A  \n",
       "5         100.00                  ~90%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuraciones originales vs optimizadas\n",
    "configs = {\n",
    "    'Modelo': ['Random Forest', 'Random Forest (opt)', \n",
    "              'Extra Trees', 'Extra Trees (opt)',\n",
    "              'Bagging con LR', 'Bagging con LR (opt)'],\n",
    "    'n_estimators': [100, 25, 100, 25, 100, 10],\n",
    "    'max_depth': ['None', 5, 'None', 5, 'N/A', 'N/A'],\n",
    "    'min_samples_split': [2, 2, 2, 10, 'N/A', 'N/A'],\n",
    "    'min_samples_leaf': [1, 2, 1, 1, 'N/A', 'N/A'],\n",
    "    'max_samples': ['N/A', 'N/A', 'N/A', 'N/A', 1.0, 0.5],\n",
    "    'max_features': ['N/A', 'N/A', 'N/A', 'N/A', 1.0, 1.0],\n",
    "    'bootstrap': ['True', 'True', 'True', 'True', 'True', 'False'],\n",
    "    'bootstrap_features': ['False', 'False', 'False', 'False', 'False', 'False'],\n",
    "    'Accuracy Test': [93.56, 99.42, 97.08, 100.0, 94.15, 100.0],\n",
    "    'Reducción Complejidad': ['N/A', '~75%', 'N/A', '~75%', 'N/A', '~90%']\n",
    "}\n",
    "\n",
    "# Crear DataFrame\n",
    "comparison_df = pd.DataFrame(configs)\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"Tabla 3.6. Comparación de configuraciones: modelos originales vs optimizados\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c987193-f253-4930-be54-ba515179fede",
   "metadata": {},
   "source": [
    "Los modelos optimizados muestran resultados variados tras la nueva partición de datos (70-30): Extra Trees y Bagging con LR mantienen el rendimiento perfecto (100% de exactitud), mientras que Random Forest muestra una ligera reducción a 99.42%. En cuanto al comportamiento en entrenamiento, Extra Trees presenta una exactitud de 99.75% frente al 100% anterior, lo que podría indicar menor tendencia al sobreajuste.\n",
    "\n",
    "Esta comparación actualizada revela varios aspectos interesantes:\n",
    "\n",
    "1. La reducción en el número de árboles/estimadores ahora es del 75% para Random Forest y Extra Trees (de 100 a 25), menor que la reducción del 90% observada previamente, sugiriendo que con más datos de prueba se requiere mayor complejidad para mantener el rendimiento.\n",
    "\n",
    "2. Para Random Forest y Extra Trees, la profundidad máxima óptima es ahora de 5 niveles (más restrictiva que los 10 niveles anteriores), lo que indica que modelos más simples pueden capturar eficazmente los patrones tras la nueva partición.\n",
    "\n",
    "3. Para Bagging con LR, la proporción de muestras se mantiene al 50%, pero ahora el bootstrap está desactivado, lo que representa un cambio en la estrategia de muestreo para adaptarse a la nueva distribución de datos.\n",
    "\n",
    "4. Con la nueva partición 70-30, que proporciona una evaluación más robusta, Extra Trees destaca particularmente al mantener el 100% de exactitud a pesar de la reducción en complejidad, mientras que Random Forest experimenta una mínima degradación.\n",
    "\n",
    "La capacidad de mantener un rendimiento excepcional con configuraciones simplificadas, incluso con una evaluación más exigente (conjunto de prueba mayor), confirma que los patrones en este conjunto de datos son altamente consistentes y bien definidos tras el preprocesamiento y selección de características adecuados. No obstante, la necesidad de más estimadores revela la importancia de equilibrar adecuadamente la complejidad del modelo con la proporción de datos destinados a entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa77985-134e-446d-9db9-b7f245e47a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos optimizados y datos guardados correctamente para la fase de explicabilidad.\n",
      "Archivo guardado en: data/optimizados/modelos_optimizados.pkl\n",
      "Contiene 18 características y 171 muestras de prueba.\n"
     ]
    }
   ],
   "source": [
    "# Crear directorio para los modelos optimizados si no existe\n",
    "os.makedirs('data/optimizados', exist_ok=True)\n",
    "\n",
    "# Guardar los modelos optimizados y datos necesarios\n",
    "optimized_data = {\n",
    "    'random_forest': best_rf,\n",
    "    'extra_trees': best_et,\n",
    "    'bagging_lr': best_bagging_lr,\n",
    "    'X_train': X_train_model,\n",
    "    'X_test': X_test_model,\n",
    "    'y_train': y_train_model,\n",
    "    'y_test': y_test_model,\n",
    "    'feature_names': X_train_model.columns.tolist()\n",
    "}\n",
    "\n",
    "# Guardar en archivo\n",
    "with open('data/optimizados/modelos_optimizados.pkl', 'wb') as f:\n",
    "    pickle.dump(optimized_data, f)\n",
    "\n",
    "print(\"Modelos optimizados y datos guardados correctamente para la fase de explicabilidad.\")\n",
    "print(f\"Archivo guardado en: data/optimizados/modelos_optimizados.pkl\")\n",
    "print(f\"Contiene {len(optimized_data['feature_names'])} características y {len(optimized_data['y_test'])} muestras de prueba.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181a684-4060-4df5-9521-8ec18d8796ac",
   "metadata": {},
   "source": [
    "# <font color=\"#000000\"> 5. Conclusiones</font><a id=\"section5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215ecd5-eeec-4309-8f85-90f5e138d743",
   "metadata": {},
   "source": [
    "A lo largo de este trabajo hemos aplicado algoritmos de Random Forest y otras técnicas ensemble al conjunto de datos \"Breast Cancer Wisconsin (Diagnostic)\" para la clasificación de tumores mamarios. El análisis exploratorio inicial mostró características con alto valor discriminativo, principalmente relacionadas con concavidad y puntos cóncavos, que presentaron diferencias estadísticamente significativas entre clases. La presencia de distribuciones no normales, correlaciones elevadas entre variables de tamaño y valores atípicos determinó nuestra estrategia de preprocesamiento adaptativo.\n",
    "\n",
    "La implementación de transformaciones específicas según el nivel de asimetría de cada variable, seguida por una normalización robusta por clase, mejoró significativamente las propiedades estadísticas de los datos, reduciendo la asimetría media en un 84.48% y la curtosis media en un 99.48%. El análisis de redundancia mediante clustering jerárquico complementado por métodos de selección (Random Forest, Extra Trees, ANOVA F-value e Información Mutua) nos permitió reducir la dimensionalidad en un 43.3%, conservando las variables con mayor poder discriminativo.\n",
    "\n",
    "Los resultados de modelado mostraron un rendimiento perfecto (100% de exactitud) para los modelos ensemble aplicados a datos preprocesados, superando a sus equivalentes con datos originales (92-96%). Esta diferencia cuantifica el impacto de nuestras técnicas de preprocesamiento y selección de variables. No obstante, este rendimiento perfecto requiere consideración metodológica, pues podría sugerir cierta adaptación específica a la partición de prueba utilizada. La optimización de hiperparámetros consiguió reducir la complejidad de los modelos en un 90-95% sin comprometer su capacidad predictiva, lo que evidencia que la estructura subyacente del problema es más simple de lo inicialmente estimado.\n",
    "\n",
    "Estos resultados destacan el valor de combinar técnicas de preprocesamiento adaptativo con algoritmos ensemble para problemas de clasificación biomédica. Las variables relacionadas con irregularidades morfológicas (concavidad) demuestran ser determinantes en la identificación de malignidad, alineándose con el conocimiento médico existente sobre patología tumoral. El trabajo realizado proporciona una metodología replicable para el análisis de datos biomédicos con aplicación potencial en sistemas de apoyo al diagnóstico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
